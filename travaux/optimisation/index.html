<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projets d'Optimisation</title>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <main>
        <section>
            <h1>Projets d'Optimisation</h1>
            <p>Voici les détails de mes projets en optimisation.</p>
            <!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <title>Exercice : Conditions d’optimalité et descente de gradient</title>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <style>
    body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
    h1, h2 { color: #2c3e50; }
    code, pre { background: #f4f4f4; padding: 8px; border-radius: 6px; }
    pre { overflow-x: auto; }
    .formula { background: #eef; padding: 6px; border-radius: 4px; }
  </style>
</head>
<body>
  <h1>Exercice : Conditions d’optimalité et descente de gradient</h1>

  <h2>Énoncé</h2>
  <p>
  Soit l’espace euclidien \(E=\mathbb{R}^n\) muni du produit scalaire canonique.
  On fixe \(y \in E\), \(y \neq 0\), et on considère :
  \[
  f(x) = \langle x, y \rangle e^{-\|x\|^2}.
  \]
  Question : Calculer le gradient de \(f\), puis mettre en place une méthode de descente de gradient.
  </p>

  <h2>1. Calcul du gradient</h2>
  <p>
  En posant \(\beta(x)=\langle x,y\rangle\), \(s(x)=e^{-\|x\|^2}\),
  on a :
  \[
  \nabla f(x) = e^{-\|x\|^2}\big(y - 2\langle x,y\rangle x\big).
  \]
  </p>

  <h2>2. Méthode de descente de gradient</h2>
  <p>
  On construit la suite \((x_k)\) par :
  \[
  x_{k+1} = x_k - \eta \nabla f(x_k),
  \]
  avec \(\eta>0\).  
  Critères d’arrêt : norme du pas, norme du gradient ou nombre d’itérations.
  </p>

  <h2>3. Code général en Python</h2>
  <pre><code class="python">
import numpy as np

def gradient_descent(grad, x0, lr=0.1, max_iter=1000, tol=1e-6):
    x = np.array(x0, dtype=float)
    history = [x.copy()]
    for k in range(max_iter):
        g = grad(x)
        x_new = x - lr * g
        history.append(x_new.copy())
        if np.linalg.norm(x_new - x) < tol:
            break
        x = x_new
    return np.array(history)
  </code></pre>

  <h2>4. Application à \(f(x)=\langle x,y\rangle e^{-\|x\|^2}\)</h2>
  <pre><code class="python">
import matplotlib.pyplot as plt

def f_xy(x, y):
    return np.dot(x, y) * np.exp(-np.linalg.norm(x)**2)

def grad_f_xy(x, y):
    return np.exp(-np.linalg.norm(x)**2) * (y - 2*np.dot(x,y)*x)

# paramètres
y = np.array([1.0, -2.0])
x0 = np.array([0.8, 0.8])
history = gradient_descent(lambda x: grad_f_xy(x,y), x0, lr=0.2)

# tracé
plt.plot(history[:,0], history[:,1], 'o-', color='red')
plt.title("Trajectoire de la descente de gradient")
plt.show()
  </code></pre>

</body>
</html>

        </section>
    </main>
</body>
</html>
